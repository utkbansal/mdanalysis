<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>3.2.6.1.1. Ensemble Similarity Calculations — MDAnalysis.analysis.encore.similarity &mdash; MDAnalysis 0.16.0-dev0 documentation</title>
    
    <link rel="stylesheet" href="../../../_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../',
        VERSION:     '0.16.0-dev0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="search" type="application/opensearchdescription+xml"
          title="Search within MDAnalysis 0.16.0-dev0 documentation"
          href="../../../_static/opensearch.xml"/>
    <link rel="shortcut icon" href="../../../_static/mdanalysis-logo.ico"/>
    <link rel="top" title="MDAnalysis 0.16.0-dev0 documentation" href="../../../index.html" />
    <link rel="up" title="3.2.6. ENCORE Ensemble Similarity Calculations — MDAnalysis.analysis.encore" href="../encore.html" />
    <link rel="next" title="3.2.6.1.2. Clustering" href="clustering.html" />
    <link rel="prev" title="3.2.6. ENCORE Ensemble Similarity Calculations — MDAnalysis.analysis.encore" href="../encore.html" /> 
  </head>
  <body role="document">
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="clustering.html" title="3.2.6.1.2. Clustering"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="../encore.html" title="3.2.6. ENCORE Ensemble Similarity Calculations — MDAnalysis.analysis.encore"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../index.html">MDAnalysis 0.16.0-dev0 documentation</a> &raquo;</li>
          <li class="nav-item nav-item-1"><a href="../../analysis_modules.html" >3. Analysis modules</a> &raquo;</li>
          <li class="nav-item nav-item-2"><a href="../encore.html" accesskey="U">3.2.6. ENCORE Ensemble Similarity Calculations &#8212; <code class="docutils literal"><span class="pre">MDAnalysis.analysis.encore</span></code></a> &raquo;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../../index.html">
              <img class="logo" src="../../../_static/mdanalysis-logo-200x150.png" alt="Logo"/>
            </a></p>
  <h3><a href="../../../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">3.2.6.1.1. Ensemble Similarity Calculations &#8212; <code class="docutils literal"><span class="pre">MDAnalysis.analysis.encore.similarity</span></code></a><ul>
<li><a class="reference internal" href="#functions-for-ensemble-comparisons">3.2.6.1.1.1. Functions for ensemble comparisons</a></li>
<li><a class="reference internal" href="#function-reference">3.2.6.1.1.2. Function reference</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="../encore.html"
                        title="previous chapter">3.2.6. ENCORE Ensemble Similarity Calculations &#8212; <code class="docutils literal"><span class="pre">MDAnalysis.analysis.encore</span></code></a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="clustering.html"
                        title="next chapter">3.2.6.1.2. Clustering</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../../_sources/documentation_pages/analysis/encore/similarity.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <span class="target" id="module-MDAnalysis.analysis.encore.similarity"></span><div class="section" id="ensemble-similarity-calculations-mdanalysis-analysis-encore-similarity">
<h1>3.2.6.1.1. Ensemble Similarity Calculations &#8212; <a class="reference internal" href="#module-MDAnalysis.analysis.encore.similarity" title="MDAnalysis.analysis.encore.similarity"><code class="xref py py-mod docutils literal"><span class="pre">MDAnalysis.analysis.encore.similarity</span></code></a><a class="headerlink" href="#ensemble-similarity-calculations-mdanalysis-analysis-encore-similarity" title="Permalink to this headline">¶</a></h1>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Author:</th><td class="field-body">Matteo Tiberti, Wouter Boomsma, Tone Bengtsen</td>
</tr>
<tr class="field-even field"><th class="field-name">Year:</th><td class="field-body">2015-2016</td>
</tr>
<tr class="field-odd field"><th class="field-name">Copyright:</th><td class="field-body">GNU Public License v3</td>
</tr>
<tr class="field-even field"><th class="field-name">Maintainer:</th><td class="field-body">Matteo Tiberti &lt;<a class="reference external" href="mailto:matteo&#46;tiberti&#37;&#52;&#48;gmail&#46;com">matteo<span>&#46;</span>tiberti<span>&#64;</span>gmail<span>&#46;</span>com</a>&gt;, mtiberti on github</td>
</tr>
</tbody>
</table>
<div class="versionadded">
<p><span class="versionmodified">New in version 0.16.0.</span></p>
</div>
<p>The module contains implementations of similarity measures between protein
ensembles described in <a class="reference internal" href="#lindorff-larsen2009" id="id1">[Lindorff-Larsen2009]</a>. The implementation and examples
are described in <a class="reference internal" href="../../references.html#tiberti2015" id="id2">[Tiberti2015]</a>.</p>
<p>The module includes facilities for handling ensembles and trajectories through
the <code class="xref py py-class docutils literal"><span class="pre">Universe</span></code> class, performing clustering or dimensionality reduction
of the ensemble space, estimating multivariate probability distributions from
the input data, and more. ENCORE can be used to compare experimental and
simulation-derived ensembles, as well as estimate the convergence of
trajectories from time-dependent simulations.</p>
<p>ENCORE includes three different methods for calculations of similarity measures
between ensembles implemented in individual functions:</p>
<ul class="simple">
<li><strong>Harmonic Ensemble Similarity</strong> : <a class="reference internal" href="#MDAnalysis.analysis.encore.similarity.hes" title="MDAnalysis.analysis.encore.similarity.hes"><code class="xref py py-func docutils literal"><span class="pre">hes()</span></code></a></li>
<li><strong>Clustering Ensemble Similarity</strong> : <a class="reference internal" href="#MDAnalysis.analysis.encore.similarity.ces" title="MDAnalysis.analysis.encore.similarity.ces"><code class="xref py py-func docutils literal"><span class="pre">ces()</span></code></a></li>
<li><strong>Dimensional Reduction Ensemble Similarity</strong> : <a class="reference internal" href="#MDAnalysis.analysis.encore.similarity.dres" title="MDAnalysis.analysis.encore.similarity.dres"><code class="xref py py-func docutils literal"><span class="pre">dres()</span></code></a></li>
</ul>
<p>as well as two methods to evaluate the convergence of trajectories:</p>
<ul class="simple">
<li><strong>Clustering based convergence evaluation</strong> : <a class="reference internal" href="#MDAnalysis.analysis.encore.similarity.ces_convergence" title="MDAnalysis.analysis.encore.similarity.ces_convergence"><code class="xref py py-func docutils literal"><span class="pre">ces_convergence()</span></code></a></li>
<li><strong>Dimensionality-reduction based convergence evaluation</strong> : <a class="reference internal" href="#MDAnalysis.analysis.encore.similarity.dres_convergence" title="MDAnalysis.analysis.encore.similarity.dres_convergence"><code class="xref py py-func docutils literal"><span class="pre">dres_convergence()</span></code></a></li>
</ul>
<p>When using this module in published work please cite <a class="reference internal" href="../../references.html#tiberti2015" id="id3">[Tiberti2015]</a>.</p>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="lindorff-larsen2009" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[Lindorff-Larsen2009]</a></td><td>Similarity Measures for Protein Ensembles. Lindorff-Larsen, K. Ferkinghoff-Borg, J. PLoS ONE 2008, 4, e4203.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="tiberti2015" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Tiberti2015]</td><td><em>(<a class="fn-backref" href="#id2">1</a>, <a class="fn-backref" href="#id3">2</a>, <a class="fn-backref" href="#id4">3</a>, <a class="fn-backref" href="#id5">4</a>, <a class="fn-backref" href="#id6">5</a>, <a class="fn-backref" href="#id7">6</a>, <a class="fn-backref" href="#id8">7</a>, <a class="fn-backref" href="#id9">8</a>, <a class="fn-backref" href="#id10">9</a>)</em> ENCORE: Software for Quantitative Ensemble Comparison. Matteo Tiberti, Elena Papaleo, Tone Bengtsen, Wouter Boomsma, Kresten Lindorff- Larsen. PLoS Comput Biol. 2015, 11</td></tr>
</tbody>
</table>
<p class="rubric" id="examples">Examples</p>
<p>The examples show how to use ENCORE to calculate a similarity measurement
of two simple ensembles. The ensembles are obtained from the MDAnalysis
test suite for two different simulations of the protein AdK. To run the
examples first execute:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">MDAnalysis</span> <span class="kn">import</span> <span class="n">Universe</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">MDAnalysis.analysis.encore</span> <span class="kn">as</span> <span class="nn">encore</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">MDAnalysis.tests.datafiles</span> <span class="kn">import</span> <span class="n">PSF</span><span class="p">,</span> <span class="n">DCD</span><span class="p">,</span> <span class="n">DCD2</span>
</pre></div>
</div>
<p>To calculate the Harmonic Ensemble Similarity (<a class="reference internal" href="#MDAnalysis.analysis.encore.similarity.hes" title="MDAnalysis.analysis.encore.similarity.hes"><code class="xref py py-func docutils literal"><span class="pre">hes()</span></code></a>)
two ensemble objects are first created and then used for calculation:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ens1</span> <span class="o">=</span> <span class="n">Universe</span><span class="p">(</span><span class="n">PSF</span><span class="p">,</span> <span class="n">DCD</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ens2</span> <span class="o">=</span> <span class="n">Universe</span><span class="p">(</span><span class="n">PSF</span><span class="p">,</span> <span class="n">DCD2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">encore</span><span class="o">.</span><span class="n">hes</span><span class="p">([</span><span class="n">ens1</span><span class="p">,</span> <span class="n">ens2</span><span class="p">])</span>
<span class="go">(array([[        0.        ,  38279683.95892926],</span>
<span class="go">        [ 38279683.95892926,         0.        ]]), None)</span>
</pre></div>
</div>
<p>Here None is returned in the array as the default details parameter is False.
HES can assume any non-negative value, i.e. no upper bound exists and the
measurement can therefore be used as an absolute scale.</p>
<p>The calculation of the Clustering Ensemble Similarity (<a class="reference internal" href="#MDAnalysis.analysis.encore.similarity.ces" title="MDAnalysis.analysis.encore.similarity.ces"><code class="xref py py-func docutils literal"><span class="pre">ces()</span></code></a>)
is computationally more expensive. It is based on clustering algorithms that in
turn require a similarity matrix between the frames the ensembles are made
of. The similarity matrix is derived from a distance matrix (By default a RMSD
matrix; a full RMSD matrix between each pairs of elements needs to be computed).
The RMSD matrix is automatically calculated.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ens1</span> <span class="o">=</span> <span class="n">Universe</span><span class="p">(</span><span class="n">PSF</span><span class="p">,</span> <span class="n">DCD</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ens2</span> <span class="o">=</span> <span class="n">Universe</span><span class="p">(</span><span class="n">PSF</span><span class="p">,</span> <span class="n">DCD2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">CES</span><span class="p">,</span> <span class="n">details</span> <span class="o">=</span> <span class="n">encore</span><span class="o">.</span><span class="n">ces</span><span class="p">([</span><span class="n">ens1</span><span class="p">,</span> <span class="n">ens2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">CES</span>
<span class="go">[[ 0.          0.68070702]</span>
<span class="go">[ 0.68070702  0.        ]]</span>
</pre></div>
</div>
<p>However, we may want to reuse the RMSD matrix in other calculations e.g.
running CES with different parameters or running DRES. In this
case we first compute the RMSD matrix alone:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rmsd_matrix</span> <span class="o">=</span> <span class="n">encore</span><span class="o">.</span><span class="n">get_distance_matrix</span><span class="p">(</span>
<span class="go">                                encore.utils.merge_universes([ens1, ens2]),</span>
<span class="go">                                save_matrix=&quot;rmsd.npz&quot;)</span>
</pre></div>
</div>
<p>In the above example the RMSD matrix was also saved in rmsd.npz on disk, and
so can be loaded and re-used at later times, instead of being recomputed:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rmsd_matrix</span> <span class="o">=</span> <span class="n">encore</span><span class="o">.</span><span class="n">get_distance_matrix</span><span class="p">(</span>
<span class="go">                                encore.utils.merge_universes([ens1, ens2]),</span>
<span class="go">                                load_matrix=&quot;rmsd.npz&quot;)</span>
</pre></div>
</div>
<p>For instance, the rmsd_matrix object can be re-used as input for the
Dimensional Reduction Ensemble Similarity (<a class="reference internal" href="#MDAnalysis.analysis.encore.similarity.dres" title="MDAnalysis.analysis.encore.similarity.dres"><code class="xref py py-func docutils literal"><span class="pre">dres()</span></code></a>) method.
DRES is based on the estimation of the probability density in
a dimensionally-reduced conformational space of the ensembles, obtained from
the original space using either the Stochastic Proximity Embedding algorithm or
the Principal Component Analysis.
As the algorithms require the distance matrix calculated on the original space,
we can reuse the previously-calculated RMSD matrix.
In the following example the dimensions are reduced to 3 using the
saved RMSD matrix and the default SPE dimensional reduction method.   :</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">DRES</span><span class="p">,</span><span class="n">details</span> <span class="o">=</span> <span class="n">encore</span><span class="o">.</span><span class="n">dres</span><span class="p">([</span><span class="n">ens1</span><span class="p">,</span> <span class="n">ens2</span><span class="p">],</span>
<span class="go">                               distance_matrix = rmsd_matrix)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">DRES</span>
<span class="go">[[ 0.        ,   0.67453198]</span>
<span class="go"> [  0.67453198,  0.        ]]</span>
</pre></div>
</div>
<p>In addition to the quantitative similarity estimate, the dimensional reduction
can easily be visualized, see the <code class="docutils literal"><span class="pre">Example</span></code> section in
<a class="reference internal" href="dimensionality_reduction.html#module-MDAnalysis.analysis.encore.dimensionality_reduction.reduce_dimensionality" title="MDAnalysis.analysis.encore.dimensionality_reduction.reduce_dimensionality"><code class="xref py py-mod docutils literal"><span class="pre">MDAnalysis.analysis.encore.dimensionality_reduction.reduce_dimensionality</span></code></a>.
Due to the stochastic nature of SPE, two identical ensembles will not
necessarily result in an exactly 0 estimate of the similarity, but will be very
close. For the same reason, calculating the similarity with the <a class="reference internal" href="#MDAnalysis.analysis.encore.similarity.dres" title="MDAnalysis.analysis.encore.similarity.dres"><code class="xref py py-func docutils literal"><span class="pre">dres()</span></code></a>
twice will not result in necessarily identical values but rather two very close
values.</p>
<p>It should be noted that both in <a class="reference internal" href="#MDAnalysis.analysis.encore.similarity.ces" title="MDAnalysis.analysis.encore.similarity.ces"><code class="xref py py-func docutils literal"><span class="pre">ces()</span></code></a> and <a class="reference internal" href="#MDAnalysis.analysis.encore.similarity.dres" title="MDAnalysis.analysis.encore.similarity.dres"><code class="xref py py-func docutils literal"><span class="pre">dres()</span></code></a> the similarity is
evaluated using the Jensen-Shannon divergence resulting in an upper bound of
ln(2), which indicates no similarity between the ensembles and a lower bound
of 0.0 signifying two identical ensembles. In contrast, the <a class="reference internal" href="#MDAnalysis.analysis.encore.similarity.hes" title="MDAnalysis.analysis.encore.similarity.hes"><code class="xref py py-func docutils literal"><span class="pre">hes()</span></code></a> function uses
a symmetrized version of the Kullback-Leibler divergence, which is unbounded.</p>
<div class="section" id="functions-for-ensemble-comparisons">
<h2>3.2.6.1.1.1. Functions for ensemble comparisons<a class="headerlink" href="#functions-for-ensemble-comparisons" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="MDAnalysis.analysis.encore.similarity.hes">
<code class="descclassname">MDAnalysis.analysis.encore.similarity.</code><code class="descname">hes</code><span class="sig-paren">(</span><em>ensembles</em>, <em>selection='name CA'</em>, <em>cov_estimator='shrinkage'</em>, <em>mass_weighted=True</em>, <em>align=False</em>, <em>details=False</em>, <em>estimate_error=False</em>, <em>bootstrapping_samples=100</em>, <em>calc_diagonal=False</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/MDAnalysis/analysis/encore/similarity.html#hes"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MDAnalysis.analysis.encore.similarity.hes" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the Harmonic Ensemble Similarity (HES) between ensembles using
the symmetrized version of Kullback-Leibler divergence as described
in <a class="reference internal" href="../../references.html#tiberti2015" id="id4">[Tiberti2015]</a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>ensembles</strong> (<a class="reference external" href="http://docs.python.org/library/functions.html#list" title="(in Python v2.7)"><em>list</em></a>) &#8211; List of Universe objects for similarity measurements.</li>
<li><strong>selection</strong> (<em>str, optional</em>) &#8211; Atom selection string in the MDAnalysis format. Default is &#8220;name CA&#8221;</li>
<li><strong>cov_estimator</strong> (<em>str, optional</em>) &#8211; Covariance matrix estimator method, either shrinkage, <cite>shrinkage</cite>,
or Maximum Likelyhood, <cite>ml</cite>. Default is shrinkage.</li>
<li><strong>mass_weighted</strong> (<em>bool, optional</em>) &#8211; Whether to perform mass-weighted covariance matrix estimation
(default is True).</li>
<li><strong>align</strong> (<em>bool, optional</em>) &#8211; Whether to align the ensembles before calculating their similarity.
Note: this changes the ensembles in-place, and will thus leave your
ensembles in an altered state.
(default is False)</li>
<li><strong>details</strong> (<em>bool, optional</em>) &#8211; Save the mean and covariance matrix for each
ensemble in a numpy array (default is False).</li>
<li><strong>estimate_error</strong> (<em>bool, optional</em>) &#8211; Whether to perform error estimation (default is False).</li>
<li><strong>bootstrapping_samples</strong> (<em>int, optional</em>) &#8211; Number of times the similarity matrix will be bootstrapped (default
is 100), only if estimate_error is True.</li>
<li><strong>calc_diagonal</strong> (<em>bool, optional</em>) &#8211; Whether to calculate the diagonal of the similarity scores
(i.e. the similarities of every ensemble against itself).
If this is False (default), 0.0 will be used instead.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Harmonic similarity measurements between each pair of ensembles.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy.array (bidimensional)</p>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>The method assumes that each ensemble is derived from a multivariate normal
distribution. The mean and covariance matrix are, thus, estimatated from
the distribution of each ensemble and used for comparision by the
symmetrized version of Kullback-Leibler divergence defined as:</p>
<div class="math">
\[D_{KL}(P(x) || Q(x)) = \int_{-\infty}^{\infty}P(x_i)
ln(P(x_i)/Q(x_i)) = \langle{}ln(P(x))\rangle{}_P -
\langle{}ln(Q(x))\rangle{}_P\]</div>
<p>where the <span class="math">\(\langle{}.\rangle{}_P\)</span> denotes an expectation
calculated under the distribution P.</p>
<p>For each ensemble, the  mean conformation is estimated as the average over
the ensemble, and the covariance matrix is calculated by default using a
shrinkage estimation method (or by a maximum-likelihood method,
optionally).</p>
<p>Note that the symmetrized version of the Kullback-Leibler divergence has no
upper bound (unlike the Jensen-Shannon divergence used by for instance CES and DRES).</p>
<p>When using this similarity measure, consider whether you want to align
the ensembles first (see example below).</p>
<p class="rubric">Example</p>
<p>To calculate the Harmonic Ensemble similarity, two ensembles are created
as Universe objects from a topology file and two trajectories. The
topology- and trajectory files used are obtained from the MDAnalysis
test suite for two different simulations of the protein AdK. To run the
examples see the module <a class="reference internal" href="#examples">Examples</a> for how to import the files:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ens1</span> <span class="o">=</span> <span class="n">Universe</span><span class="p">(</span><span class="n">PSF</span><span class="p">,</span> <span class="n">DCD</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ens2</span> <span class="o">=</span> <span class="n">Universe</span><span class="p">(</span><span class="n">PSF</span><span class="p">,</span> <span class="n">DCD2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">HES</span><span class="p">,</span> <span class="n">details</span> <span class="o">=</span> <span class="n">encore</span><span class="o">.</span><span class="n">hes</span><span class="p">([</span><span class="n">ens1</span><span class="p">,</span> <span class="n">ens2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">HES</span>
<span class="go">[[        0.          38279683.95892926]</span>
<span class="go"> [ 38279683.95892926         0.        ]]</span>
</pre></div>
</div>
<p>You can use the align=True option to align the ensembles first. This will
align everything to the current timestep in the first ensemble. Note that
this changes the ens1 and ens2 objects:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">encore</span><span class="o">.</span><span class="n">hes</span><span class="p">([</span><span class="n">ens1</span><span class="p">,</span> <span class="n">ens2</span><span class="p">],</span> <span class="n">align</span><span class="o">=</span><span class="bp">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">[[    0.          6880.34140106]</span>
<span class="go">[ 6880.34140106     0.        ]]</span>
</pre></div>
</div>
<p>Alternatively, for greater flexibility in how the alignment should be done
you can call the rms_fit_trj function manually:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">MDAnalysis.analysis</span> <span class="kn">import</span> <span class="n">align</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">align</span><span class="o">.</span><span class="n">rms_fit_trj</span><span class="p">(</span><span class="n">ens1</span><span class="p">,</span> <span class="n">ens1</span><span class="p">,</span> <span class="n">select</span><span class="o">=</span><span class="s2">&quot;name CA&quot;</span><span class="p">,</span> <span class="n">in_memory</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">align</span><span class="o">.</span><span class="n">rms_fit_trj</span><span class="p">(</span><span class="n">ens2</span><span class="p">,</span> <span class="n">ens1</span><span class="p">,</span> <span class="n">select</span><span class="o">=</span><span class="s2">&quot;name CA&quot;</span><span class="p">,</span> <span class="n">in_memory</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">encore</span><span class="o">.</span><span class="n">hes</span><span class="p">([</span><span class="n">ens1</span><span class="p">,</span> <span class="n">ens2</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">[[    0.          7032.19607004]</span>
<span class="go"> [ 7032.19607004     0.        ]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="MDAnalysis.analysis.encore.similarity.ces">
<code class="descclassname">MDAnalysis.analysis.encore.similarity.</code><code class="descname">ces</code><span class="sig-paren">(</span><em>ensembles</em>, <em>selection='name CA'</em>, <em>clustering_method=&lt;MDAnalysis.analysis.encore.clustering.ClusteringMethod.AffinityPropagationNative object&gt;</em>, <em>distance_matrix=None</em>, <em>estimate_error=False</em>, <em>bootstrapping_samples=10</em>, <em>ncores=1</em>, <em>calc_diagonal=False</em>, <em>allow_collapsed_result=True</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/MDAnalysis/analysis/encore/similarity.html#ces"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MDAnalysis.analysis.encore.similarity.ces" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the Clustering Ensemble Similarity (CES) between ensembles
using the Jensen-Shannon divergence as described in
<a class="reference internal" href="../../references.html#tiberti2015" id="id5">[Tiberti2015]</a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>ensembles</strong> (<a class="reference external" href="http://docs.python.org/library/functions.html#list" title="(in Python v2.7)"><em>list</em></a>) &#8211; List of ensemble objects for similarity measurements</li>
<li><strong>selection</strong> (<em>str, optional</em>) &#8211; Atom selection string in the MDAnalysis format. Default is &#8220;name CA&#8221;</li>
<li><strong>clustering_method</strong> &#8211; A single or a list of instances of the
<a class="reference internal" href="clustering.html#module-MDAnalysis.analysis.encore.clustering.ClusteringMethod" title="MDAnalysis.analysis.encore.clustering.ClusteringMethod"><code class="xref py py-class docutils literal"><span class="pre">MDAnalysis.analysis.encore.clustering.ClusteringMethod</span></code></a> classes
from the clustering module. Different parameters for the same clustering
method can be explored by adding different instances of the same
clustering class. Clustering methods options are the
Affinity Propagation (default), the DBSCAN and the KMeans. The latter
two methods need the sklearn python module installed.</li>
<li><strong>distance_matrix</strong> (<a class="reference internal" href="utils.html#MDAnalysis.analysis.encore.utils.TriangularMatrix" title="MDAnalysis.analysis.encore.utils.TriangularMatrix"><em>encore.utils.TriangularMatrix</em></a>) &#8211; Distance matrix clustering methods. If this parameter
is not supplied the matrix will be calculated on the fly.</li>
<li><strong>estimate_error</strong> (<em>bool, optional</em>) &#8211; Whether to perform error estimation (default is False).
Only bootstrapping mode is supported.</li>
<li><strong>bootstrapping_samples</strong> (<em>int, optional</em>) &#8211; number of samples to be used for estimating error.</li>
<li><strong>ncores</strong> (<em>int, optional</em>) &#8211; Maximum number of cores to be used (default is 1).</li>
<li><strong>calc_diagonal</strong> (<em>bool, optional</em>) &#8211; Whether to calculate the diagonal of the similarity scores
(i.e. the similarities of every ensemble against itself).
If this is False (default), 0.0 will be used instead.</li>
<li><strong>allow_collapsed_result</strong> (<em>bool, optional</em>) &#8211; Whether a return value of a list of one value should be collapsed
into just the value.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><p><strong>ces, details</strong> &#8211;</p>
<p>ces contains the similarity values, arranged in a numpy.array.
If only one clustering_method is provided the output will be a
2-dimensional square symmetrical numpy.array. The order of the matrix
elements depends on the order of the input ensembles: for instance, if</p>
<blockquote>
<div><p>ensemble = [ens1, ens2, ens3]</p>
</div></blockquote>
<p>the matrix elements [0,2] and [2,0] will both contain the similarity
value between ensembles ens1 and ens3.
Elaborating on the previous example, if <em>n</em> ensembles are given and <em>m</em>
clustering_methods are provided the output will be a list of <em>m</em> arrays
ordered by the input sequence of methods, each with a <em>n*x*n</em>
symmetrical similarity matrix.</p>
<p>details contains information on the clustering: the individual size of
each cluster, the centroids and the frames associated with each cluster.</p>
</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy.array, numpy.array</p>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>In the Jensen-Shannon divergence the upper bound of ln(2) signifies
no similarity between the two ensembles, the lower bound, 0.0,
signifies identical ensembles.</p>
<p>To calculate the CES, the affinity propagation method (or others, if
specified) is used to partition the whole space of conformations. The
population of each ensemble in each cluster is then taken as a probability
density function. Different probability density functions from each
ensemble are finally compared using the Jensen-Shannon divergence measure.</p>
<p class="rubric">Examples</p>
<p>To calculate the Clustering Ensemble similarity, two ensembles are
created as Universe object using a topology file and two trajectories. The
topology- and trajectory files used are obtained from the MDAnalysis
test suite for two different simulations of the protein AdK. To run the
examples see the module <a class="reference internal" href="#examples">Examples</a> for how to import the files.
Here the simplest case of just two instances of <code class="xref py py-class docutils literal"><span class="pre">Universe</span></code> is illustrated:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ens1</span> <span class="o">=</span> <span class="n">Universe</span><span class="p">(</span><span class="n">PSF</span><span class="p">,</span> <span class="n">DCD</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ens2</span> <span class="o">=</span> <span class="n">Universe</span><span class="p">(</span><span class="n">PSF</span><span class="p">,</span> <span class="n">DCD2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">CES</span><span class="p">,</span><span class="n">details</span> <span class="o">=</span> <span class="n">encore</span><span class="o">.</span><span class="n">ces</span><span class="p">([</span><span class="n">ens1</span><span class="p">,</span><span class="n">ens2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">CES</span>
<span class="go">[[ 0.          0.68070702]</span>
<span class="go"> [ 0.68070702  0.        ]]</span>
</pre></div>
</div>
<p>To use a different clustering method, set the parameter clustering_method
(Note that the sklearn module must be installed). Likewise,  different parameters
for the same clustering method can be explored by adding different
instances of the same clustering class:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">CES</span><span class="p">,</span> <span class="n">details</span> <span class="o">=</span> <span class="n">encore</span><span class="o">.</span><span class="n">ces</span><span class="p">([</span><span class="n">ens1</span><span class="p">,</span><span class="n">ens2</span><span class="p">],</span>
<span class="go">                              clustering_method = [encore.DBSCAN(eps=0.45),</span>
<span class="go">                                                   encore.DBSCAN(eps=0.50)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="s2">&quot;eps=0.45: &quot;</span><span class="p">,</span> <span class="n">CES</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">eps=0.45:  [[ 0.          0.20447236]</span>
<span class="go">[ 0.20447236  0.        ]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="s2">&quot;eps=0.5: &quot;</span><span class="p">,</span> <span class="n">CES</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="go">eps=0.5:  [[ 0.          0.25331629]</span>
<span class="go">[ 0.25331629  0.        ]]&quot;</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="MDAnalysis.analysis.encore.similarity.dres">
<code class="descclassname">MDAnalysis.analysis.encore.similarity.</code><code class="descname">dres</code><span class="sig-paren">(</span><em>ensembles</em>, <em>selection='name CA'</em>, <em>dimensionality_reduction_method=&lt;MDAnalysis.analysis.encore.dimensionality_reduction.DimensionalityReductionMethod.StochasticProximityEmbeddingNative object&gt;</em>, <em>distance_matrix=None</em>, <em>nsamples=1000</em>, <em>estimate_error=False</em>, <em>bootstrapping_samples=100</em>, <em>ncores=1</em>, <em>calc_diagonal=False</em>, <em>allow_collapsed_result=True</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/MDAnalysis/analysis/encore/similarity.html#dres"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MDAnalysis.analysis.encore.similarity.dres" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the Dimensional Reduction Ensemble Similarity (DRES) between
ensembles using the Jensen-Shannon divergence as described in
<a class="reference internal" href="../../references.html#tiberti2015" id="id6">[Tiberti2015]</a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>ensembles</strong> (<a class="reference external" href="http://docs.python.org/library/functions.html#list" title="(in Python v2.7)"><em>list</em></a>) &#8211; List of ensemble objects for similarity measurements</li>
<li><strong>selection</strong> (<em>str, optional</em>) &#8211; Atom selection string in the MDAnalysis format. Default is &#8220;name CA&#8221;</li>
<li><strong>dimensionality_reduction_method</strong> &#8211; A single or a list of instances of the DimensionalityReductionMethod
classes from the dimensionality_reduction module. Different parameters
for the same method can be explored by adding different instances of
the same dimensionality reduction class. Provided methods are the
Stochastic Proximity Embedding (default) and the Principal Component
Analysis.</li>
<li><strong>distance_matrix</strong> (<a class="reference internal" href="utils.html#MDAnalysis.analysis.encore.utils.TriangularMatrix" title="MDAnalysis.analysis.encore.utils.TriangularMatrix"><em>encore.utils.TriangularMatrix</em></a>) &#8211; conformational distance matrix, It will be calculated on the fly
from the ensemble data if it is not provided.</li>
<li><strong>nsamples</strong> (<em>int, optional</em>) &#8211; Number of samples to be drawn from the ensembles (default is 1000).
This is used to resample the density estimates and calculate the
Jensen-Shannon divergence between ensembles.</li>
<li><strong>estimate_error</strong> (<em>bool, optional</em>) &#8211; Whether to perform error estimation (default is False)</li>
<li><strong>bootstrapping_samples</strong> (<em>int, optional</em>) &#8211; number of samples to be used for estimating error.</li>
<li><strong>ncores</strong> (<em>int, optional</em>) &#8211; Maximum number of cores to be used (default is 1).</li>
<li><strong>calc_diagonal</strong> (<em>bool, optional</em>) &#8211; Whether to calculate the diagonal of the similarity scores
(i.e. the simlarities of every ensemble against itself).
If this is False (default), 0.0 will be used instead.</li>
<li><strong>allow_collapsed_result</strong> (<em>bool, optional</em>) &#8211; Whether a return value of a list of one value should be collapsed
into just the value.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><p><strong>dres, details</strong> &#8211;
dres contains the similarity values, arranged in numpy.array.
If one number of dimensions is provided as an integer,
the output will be a 2-dimensional square symmetrical numpy.array.
The order of the matrix elements depends on the order of the
input ensemble: for instance, if</p>
<blockquote>
<div><p>ensemble = [ens1, ens2, ens3]</p>
</div></blockquote>
<p>then the matrix elements [0,2] and [2,0] will both contain the
similarity value between ensembles ens1 and ens3.
Elaborating on the previous example, if <em>n</em> ensembles are given and <em>m</em>
methods are provided the output will be a list of <em>m</em> arrays
ordered by the input sequence of methods, each with a <em>n*x*n</em>
symmetrical similarity matrix.</p>
<p>details provide an array of the reduced_coordinates.</p>
</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy.array, numpy.array</p>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>To calculate the similarity, the method first projects the ensembles into
lower dimensions by using the Stochastic Proximity Embedding (or others)
algorithm. A gaussian kernel-based density estimation method is then used
to estimate the probability density for each ensemble which is then used
to compute the Jensen-Shannon divergence between each pair of ensembles.</p>
<p>In the Jensen-Shannon divergence the upper bound of ln(2) signifies
no similarity between the two ensembles, the lower bound, 0.0,
signifies identical ensembles. However, due to the stochastic nature of
the dimensional reduction in <a class="reference internal" href="#MDAnalysis.analysis.encore.similarity.dres" title="MDAnalysis.analysis.encore.similarity.dres"><code class="xref py py-func docutils literal"><span class="pre">dres()</span></code></a>, two identical ensembles will
not necessarily result in an exact 0.0 estimate of the similarity but
will be very close. For the same reason, calculating the similarity with
the <a class="reference internal" href="#MDAnalysis.analysis.encore.similarity.dres" title="MDAnalysis.analysis.encore.similarity.dres"><code class="xref py py-func docutils literal"><span class="pre">dres()</span></code></a> twice will not result in two identical numbers; small
differences have to be expected.</p>
<p class="rubric">Examples</p>
<p>To calculate the Dimensional Reduction Ensemble similarity, two ensembles
are created as Universe objects from a topology file and two trajectories.
The topology- and trajectory files used are obtained from the MDAnalysis
test suite for two different simulations of the protein AdK. To run the
examples see the module <a class="reference internal" href="#examples">Examples</a> for how to import the files.
Here the simplest case of comparing just two instances of <code class="xref py py-class docutils literal"><span class="pre">Universe</span></code> is
illustrated:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ens1</span> <span class="o">=</span> <span class="n">Universe</span><span class="p">(</span><span class="n">PSF</span><span class="p">,</span><span class="n">DCD</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ens2</span> <span class="o">=</span> <span class="n">Universe</span><span class="p">(</span><span class="n">PSF</span><span class="p">,</span><span class="n">DCD2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">DRES</span><span class="p">,</span> <span class="n">details</span> <span class="o">=</span> <span class="n">encore</span><span class="o">.</span><span class="n">dres</span><span class="p">([</span><span class="n">ens1</span><span class="p">,</span><span class="n">ens2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">DRES</span>
<span class="go">[[ 0.          0.67996043]</span>
<span class="go"> [ 0.67996043  0.        ]]</span>
</pre></div>
</div>
<p>In addition to the quantitative similarity estimate, the dimensional
reduction can easily be visualized, see the <code class="docutils literal"><span class="pre">Example</span></code> section in
<code class="xref py py-mod docutils literal"><span class="pre">MDAnalysis.analysis.encore.dimensionality_reduction.reduce_dimensionality`</span></code></p>
<p>To use a different dimensional reduction methods, simply set the
parameter dimensionality_reduction_method. Likewise, different parameters
for the same clustering method can be explored by adding different
instances of the same method  class:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">DRES</span><span class="p">,</span> <span class="n">details</span> <span class="o">=</span> <span class="n">encore</span><span class="o">.</span><span class="n">dres</span><span class="p">([</span><span class="n">ens1</span><span class="p">,</span><span class="n">ens2</span><span class="p">],</span>
<span class="go">                                dimensionality_reduction_method = encore.PrincipalComponentAnalysis(dimension=2))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">DRES</span>
<span class="go">[[ 0.          0.69314718]</span>
<span class="go"> [ 0.69314718  0.        ]]</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="function-reference">
<h2>3.2.6.1.1.2. Function reference<a class="headerlink" href="#function-reference" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt>
<code class="descclassname">MDAnalysis.analysis.encore.similarity.</code><code class="descname">ces</code><span class="sig-paren">(</span><em>ensembles</em>, <em>selection='name CA'</em>, <em>clustering_method=&lt;MDAnalysis.analysis.encore.clustering.ClusteringMethod.AffinityPropagationNative object&gt;</em>, <em>distance_matrix=None</em>, <em>estimate_error=False</em>, <em>bootstrapping_samples=10</em>, <em>ncores=1</em>, <em>calc_diagonal=False</em>, <em>allow_collapsed_result=True</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/MDAnalysis/analysis/encore/similarity.html#ces"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Calculates the Clustering Ensemble Similarity (CES) between ensembles
using the Jensen-Shannon divergence as described in
<a class="reference internal" href="../../references.html#tiberti2015" id="id7">[Tiberti2015]</a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>ensembles</strong> (<a class="reference external" href="http://docs.python.org/library/functions.html#list" title="(in Python v2.7)"><em>list</em></a>) &#8211; List of ensemble objects for similarity measurements</li>
<li><strong>selection</strong> (<em>str, optional</em>) &#8211; Atom selection string in the MDAnalysis format. Default is &#8220;name CA&#8221;</li>
<li><strong>clustering_method</strong> &#8211; A single or a list of instances of the
<a class="reference internal" href="clustering.html#module-MDAnalysis.analysis.encore.clustering.ClusteringMethod" title="MDAnalysis.analysis.encore.clustering.ClusteringMethod"><code class="xref py py-class docutils literal"><span class="pre">MDAnalysis.analysis.encore.clustering.ClusteringMethod</span></code></a> classes
from the clustering module. Different parameters for the same clustering
method can be explored by adding different instances of the same
clustering class. Clustering methods options are the
Affinity Propagation (default), the DBSCAN and the KMeans. The latter
two methods need the sklearn python module installed.</li>
<li><strong>distance_matrix</strong> (<a class="reference internal" href="utils.html#MDAnalysis.analysis.encore.utils.TriangularMatrix" title="MDAnalysis.analysis.encore.utils.TriangularMatrix"><em>encore.utils.TriangularMatrix</em></a>) &#8211; Distance matrix clustering methods. If this parameter
is not supplied the matrix will be calculated on the fly.</li>
<li><strong>estimate_error</strong> (<em>bool, optional</em>) &#8211; Whether to perform error estimation (default is False).
Only bootstrapping mode is supported.</li>
<li><strong>bootstrapping_samples</strong> (<em>int, optional</em>) &#8211; number of samples to be used for estimating error.</li>
<li><strong>ncores</strong> (<em>int, optional</em>) &#8211; Maximum number of cores to be used (default is 1).</li>
<li><strong>calc_diagonal</strong> (<em>bool, optional</em>) &#8211; Whether to calculate the diagonal of the similarity scores
(i.e. the similarities of every ensemble against itself).
If this is False (default), 0.0 will be used instead.</li>
<li><strong>allow_collapsed_result</strong> (<em>bool, optional</em>) &#8211; Whether a return value of a list of one value should be collapsed
into just the value.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><p><strong>ces, details</strong> &#8211;</p>
<p>ces contains the similarity values, arranged in a numpy.array.
If only one clustering_method is provided the output will be a
2-dimensional square symmetrical numpy.array. The order of the matrix
elements depends on the order of the input ensembles: for instance, if</p>
<blockquote>
<div><p>ensemble = [ens1, ens2, ens3]</p>
</div></blockquote>
<p>the matrix elements [0,2] and [2,0] will both contain the similarity
value between ensembles ens1 and ens3.
Elaborating on the previous example, if <em>n</em> ensembles are given and <em>m</em>
clustering_methods are provided the output will be a list of <em>m</em> arrays
ordered by the input sequence of methods, each with a <em>n*x*n</em>
symmetrical similarity matrix.</p>
<p>details contains information on the clustering: the individual size of
each cluster, the centroids and the frames associated with each cluster.</p>
</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy.array, numpy.array</p>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>In the Jensen-Shannon divergence the upper bound of ln(2) signifies
no similarity between the two ensembles, the lower bound, 0.0,
signifies identical ensembles.</p>
<p>To calculate the CES, the affinity propagation method (or others, if
specified) is used to partition the whole space of conformations. The
population of each ensemble in each cluster is then taken as a probability
density function. Different probability density functions from each
ensemble are finally compared using the Jensen-Shannon divergence measure.</p>
<p class="rubric">Examples</p>
<p>To calculate the Clustering Ensemble similarity, two ensembles are
created as Universe object using a topology file and two trajectories. The
topology- and trajectory files used are obtained from the MDAnalysis
test suite for two different simulations of the protein AdK. To run the
examples see the module <a class="reference internal" href="#examples">Examples</a> for how to import the files.
Here the simplest case of just two instances of <code class="xref py py-class docutils literal"><span class="pre">Universe</span></code> is illustrated:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ens1</span> <span class="o">=</span> <span class="n">Universe</span><span class="p">(</span><span class="n">PSF</span><span class="p">,</span> <span class="n">DCD</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ens2</span> <span class="o">=</span> <span class="n">Universe</span><span class="p">(</span><span class="n">PSF</span><span class="p">,</span> <span class="n">DCD2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">CES</span><span class="p">,</span><span class="n">details</span> <span class="o">=</span> <span class="n">encore</span><span class="o">.</span><span class="n">ces</span><span class="p">([</span><span class="n">ens1</span><span class="p">,</span><span class="n">ens2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">CES</span>
<span class="go">[[ 0.          0.68070702]</span>
<span class="go"> [ 0.68070702  0.        ]]</span>
</pre></div>
</div>
<p>To use a different clustering method, set the parameter clustering_method
(Note that the sklearn module must be installed). Likewise,  different parameters
for the same clustering method can be explored by adding different
instances of the same clustering class:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">CES</span><span class="p">,</span> <span class="n">details</span> <span class="o">=</span> <span class="n">encore</span><span class="o">.</span><span class="n">ces</span><span class="p">([</span><span class="n">ens1</span><span class="p">,</span><span class="n">ens2</span><span class="p">],</span>
<span class="go">                              clustering_method = [encore.DBSCAN(eps=0.45),</span>
<span class="go">                                                   encore.DBSCAN(eps=0.50)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="s2">&quot;eps=0.45: &quot;</span><span class="p">,</span> <span class="n">CES</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">eps=0.45:  [[ 0.          0.20447236]</span>
<span class="go">[ 0.20447236  0.        ]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="s2">&quot;eps=0.5: &quot;</span><span class="p">,</span> <span class="n">CES</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="go">eps=0.5:  [[ 0.          0.25331629]</span>
<span class="go">[ 0.25331629  0.        ]]&quot;</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="MDAnalysis.analysis.encore.similarity.ces_convergence">
<code class="descclassname">MDAnalysis.analysis.encore.similarity.</code><code class="descname">ces_convergence</code><span class="sig-paren">(</span><em>original_ensemble</em>, <em>window_size</em>, <em>selection='name CA'</em>, <em>clustering_method=&lt;MDAnalysis.analysis.encore.clustering.ClusteringMethod.AffinityPropagationNative object&gt;</em>, <em>ncores=1</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/MDAnalysis/analysis/encore/similarity.html#ces_convergence"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MDAnalysis.analysis.encore.similarity.ces_convergence" title="Permalink to this definition">¶</a></dt>
<dd><p>Use the CES to evaluate the convergence of the ensemble/trajectory.
CES will be calculated between the whole trajectory contained in an
ensemble and windows of such trajectory of increasing sizes, so that
the similarity values should gradually drop to zero. The rate at which
the value reach zero will be indicative of how much the trajectory
keeps on resampling the same regions of the conformational space, and
therefore of convergence.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>original_ensemble</strong> (<a class="reference internal" href="../../core/AtomGroup.html#MDAnalysis.core.AtomGroup.Universe" title="MDAnalysis.core.AtomGroup.Universe"><code class="xref py py-class docutils literal"><span class="pre">Universe</span></code></a> object) &#8211; ensemble containing the trajectory whose convergence has to estimated</li>
<li><strong>window_size</strong> (<a class="reference external" href="http://docs.python.org/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; Size of window to be used, in number of frames</li>
<li><strong>selection</strong> (<em>str, optional</em>) &#8211; Atom selection string in the MDAnalysis format. Default is &#8220;name CA&#8221;</li>
<li><strong>clustering_method</strong> (<a class="reference internal" href="clustering.html#module-MDAnalysis.analysis.encore.clustering.ClusteringMethod" title="MDAnalysis.analysis.encore.clustering.ClusteringMethod"><em>MDAnalysis.analysis.encore.clustering.ClusteringMethod</em></a>) &#8211; A single or a list of instances of the ClusteringMethod classes from
the clustering module. Different parameters for the same clustering
method can be explored by adding different instances of the same
clustering class.</li>
<li><strong>ncores</strong> (<em>int, optional</em>) &#8211; Maximum number of cores to be used (default is 1).</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>out</strong> &#8211;
array of shape (number_of_frames / window_size, preference_values).</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">np.array</p>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Example</p>
<p>To calculate the convergence of a trajectory using the clustering ensemble
similarity method a Universe object is created from a topology file and the
trajectory. The topology- and trajectory files used are obtained from the
MDAnalysis test suite for two different simulations of the protein AdK.
To run the examples see the module <a class="reference internal" href="#examples">Examples</a> for how to import the files.
Here the simplest case of evaluating the convergence is illustrated by
splitting the trajectory into a window_size of 10 frames :</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ens1</span> <span class="o">=</span> <span class="n">Universe</span><span class="p">(</span><span class="n">PSF</span><span class="p">,</span><span class="n">DCD</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ces_conv</span> <span class="o">=</span> <span class="n">encore</span><span class="o">.</span><span class="n">ces_convergence</span><span class="p">(</span><span class="n">ens1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">ces_conv</span>
<span class="go">[[ 0.48194205]</span>
<span class="go">[ 0.40284672]</span>
<span class="go">[ 0.31699026]</span>
<span class="go">[ 0.25220447]</span>
<span class="go">[ 0.19829817]</span>
<span class="go">[ 0.14642725]</span>
<span class="go">[ 0.09911411]</span>
<span class="go">[ 0.05667391]</span>
<span class="go">[ 0.        ]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="MDAnalysis.analysis.encore.similarity.clustering_ensemble_similarity">
<code class="descclassname">MDAnalysis.analysis.encore.similarity.</code><code class="descname">clustering_ensemble_similarity</code><span class="sig-paren">(</span><em>cc</em>, <em>ens1</em>, <em>ens1_id</em>, <em>ens2</em>, <em>ens2_id</em>, <em>selection='name CA'</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/MDAnalysis/analysis/encore/similarity.html#clustering_ensemble_similarity"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MDAnalysis.analysis.encore.similarity.clustering_ensemble_similarity" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>Clustering ensemble similarity: calculate the probability densities from</dt>
<dd>the clusters and calculate discrete Jensen-Shannon divergence.</dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>cc</strong> (<em>encore.clustering.ClustersCollection</em>) &#8211; Collection from cluster calculated by a clustering algorithm
(e.g. Affinity propagation)</li>
<li><strong>ens1</strong> (<a class="reference internal" href="../../core/AtomGroup.html#MDAnalysis.core.AtomGroup.Universe" title="MDAnalysis.core.AtomGroup.Universe"><code class="xref py py-class docutils literal"><span class="pre">Universe</span></code></a>) &#8211; First ensemble to be used in comparison</li>
<li><strong>ens1_id</strong> (<a class="reference external" href="http://docs.python.org/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; First ensemble id as detailed in the ClustersCollection metadata</li>
<li><strong>ens2</strong> (<a class="reference internal" href="../../core/AtomGroup.html#MDAnalysis.core.AtomGroup.Universe" title="MDAnalysis.core.AtomGroup.Universe"><code class="xref py py-class docutils literal"><span class="pre">Universe</span></code></a>) &#8211; Second ensemble to be used in comparison</li>
<li><strong>ens2_id</strong> (<a class="reference external" href="http://docs.python.org/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; Second ensemble id as detailed in the ClustersCollection metadata</li>
<li><strong>selection</strong> (<a class="reference external" href="http://docs.python.org/library/functions.html#str" title="(in Python v2.7)"><em>str</em></a>) &#8211; Atom selection string in the MDAnalysis format. Default is &#8220;name CA&#8221;.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>djs</strong> &#8211;
Jensen-Shannon divergence between the two ensembles, as calculated by
the clustering ensemble similarity method</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="http://docs.python.org/library/functions.html#float" title="(in Python v2.7)">float</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="MDAnalysis.analysis.encore.similarity.cumulative_clustering_ensemble_similarity">
<code class="descclassname">MDAnalysis.analysis.encore.similarity.</code><code class="descname">cumulative_clustering_ensemble_similarity</code><span class="sig-paren">(</span><em>cc</em>, <em>ens1_id</em>, <em>ens2_id</em>, <em>ens1_id_min=1</em>, <em>ens2_id_min=1</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/MDAnalysis/analysis/encore/similarity.html#cumulative_clustering_ensemble_similarity"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MDAnalysis.analysis.encore.similarity.cumulative_clustering_ensemble_similarity" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate clustering ensemble similarity between joined ensembles.
This means that, after clustering has been performed, some ensembles are
merged and the dJS is calculated between the probability distributions of
the two clusters groups. In particular, the two ensemble groups are defined
by their ensembles id: one of the two joined ensembles will comprise all
the ensembles with id [ens1_id_min, ens1_id], and the other ensembles will
comprise all the ensembles with id [ens2_id_min, ens2_id].</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>cc</strong> (<em>encore.ClustersCollection</em>) &#8211; Collection from cluster calculated by a clustering algorithm
(e.g. Affinity propagation)</li>
<li><strong>ens1_id</strong> (<a class="reference external" href="http://docs.python.org/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; First ensemble id as detailed in the ClustersCollection
metadata</li>
<li><strong>ens2_id</strong> (<a class="reference external" href="http://docs.python.org/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; Second ensemble id as detailed in the ClustersCollection
metadata</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>djs</strong> &#8211;
Jensen-Shannon divergence between the two ensembles, as
calculated by the clustering ensemble similarity method</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="http://docs.python.org/library/functions.html#float" title="(in Python v2.7)">float</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="MDAnalysis.analysis.encore.similarity.cumulative_gen_kde_pdfs">
<code class="descclassname">MDAnalysis.analysis.encore.similarity.</code><code class="descname">cumulative_gen_kde_pdfs</code><span class="sig-paren">(</span><em>embedded_space</em>, <em>ensemble_assignment</em>, <em>nensembles</em>, <em>nsamples</em>, <em>ens_id_min=1</em>, <em>ens_id_max=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/MDAnalysis/analysis/encore/similarity.html#cumulative_gen_kde_pdfs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MDAnalysis.analysis.encore.similarity.cumulative_gen_kde_pdfs" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate Kernel Density Estimates (KDE) from embedded spaces and
elaborate the coordinates for later use. However, consider more than
one ensemble as the space on which the KDE will be generated. In
particular, will use ensembles with ID [ens_id_min, ens_id_max].</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>embedded_space</strong> (<a class="reference external" href="http://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html#numpy.array" title="(in NumPy v1.11)"><em>numpy.array</em></a>) &#8211; Array containing the coordinates of the embedded space</li>
<li><strong>ensemble_assignment</strong> (<a class="reference external" href="http://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html#numpy.array" title="(in NumPy v1.11)"><em>numpy.array</em></a>) &#8211; array containing one int per ensemble conformation. These allow
to distinguish, in the complete embedded space, which
conformations belong to each ensemble. For instance if
ensemble_assignment is [1,1,1,1,2,2], it means that the first
four conformations belong to ensemble 1 and the last two
to ensemble 2</li>
<li><strong>nensembles</strong> (<a class="reference external" href="http://docs.python.org/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; Number of ensembles</li>
<li><strong>nsamples</strong> (<a class="reference external" href="http://docs.python.org/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; Samples to be drawn from the ensembles. Will be required in a later
stage in order to calculate dJS.</li>
<li><strong>ens_id_min</strong> (<a class="reference external" href="http://docs.python.org/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; Minimum ID of the ensemble to be considered; see description</li>
<li><strong>ens_id_max</strong> (<a class="reference external" href="http://docs.python.org/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; Maximum ID of the ensemble to be considered; see description. If None,
it will be set to the maximum possible value given the number of
ensembles.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><strong>kdes</strong> (<em>scipy.stats.gaussian_kde</em>) &#8211;
KDEs calculated from ensembles</li>
<li><strong>resamples</strong> (<em>list of numpy.array</em>) &#8211;
For each KDE, draw samples according to the probability
distribution of the kde mixture model</li>
<li><strong>embedded_ensembles</strong> (<em>list of numpy.array</em>) &#8211;
List of numpy.array containing, each one, the elements of the
embedded space belonging to a certain ensemble</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="MDAnalysis.analysis.encore.similarity.dimred_ensemble_similarity">
<code class="descclassname">MDAnalysis.analysis.encore.similarity.</code><code class="descname">dimred_ensemble_similarity</code><span class="sig-paren">(</span><em>kde1</em>, <em>resamples1</em>, <em>kde2</em>, <em>resamples2</em>, <em>ln_P1_exp_P1=None</em>, <em>ln_P2_exp_P2=None</em>, <em>ln_P1P2_exp_P1=None</em>, <em>ln_P1P2_exp_P2=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/MDAnalysis/analysis/encore/similarity.html#dimred_ensemble_similarity"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MDAnalysis.analysis.encore.similarity.dimred_ensemble_similarity" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the Jensen-Shannon divergence according the the
Dimensionality reduction method. In this case, we have continuous
probability densities, this we need to integrate over the measurable
space. The aim is to first calculate the Kullback-Liebler divergence, which
is defined as:</p>
<div class="math">
\[D_{KL}(P(x) || Q(x)) = \int_{-\infty}^{\infty}P(x_i) ln(P(x_i)/Q(x_i)) = \langle{}ln(P(x))\rangle{}_P - \langle{}ln(Q(x))\rangle{}_P\]</div>
<p>where the <span class="math">\(\langle{}.\rangle{}_P\)</span> denotes an expectation calculated
under the distribution P. We can, thus, just estimate the expectation
values of the components to get an estimate of dKL.
Since the Jensen-Shannon distance is actually  more complex, we need to
estimate four expectation values:</p>
<div class="math">
\[\langle{}log(P(x))\rangle{}_P\]\[\langle{}log(Q(x))\rangle{}_Q\]\[\langle{}log(0.5*(P(x)+Q(x)))\rangle{}_P\]\[\langle{}log(0.5*(P(x)+Q(x)))\rangle{}_Q\]</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>kde1</strong> (<a class="reference external" href="http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gaussian_kde.html#scipy.stats.gaussian_kde" title="(in SciPy v0.18.1)"><em>scipy.stats.gaussian_kde</em></a>) &#8211; Kernel density estimation for ensemble 1</li>
<li><strong>resamples1</strong> (<a class="reference external" href="http://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html#numpy.array" title="(in NumPy v1.11)"><em>numpy.array</em></a>) &#8211; Samples drawn according do kde1. Will be used as samples to
calculate the expected values according to &#8216;P&#8217; as detailed before.</li>
<li><strong>kde2</strong> (<a class="reference external" href="http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gaussian_kde.html#scipy.stats.gaussian_kde" title="(in SciPy v0.18.1)"><em>scipy.stats.gaussian_kde</em></a>) &#8211; Kernel density estimation for ensemble 2</li>
<li><strong>resamples2</strong> (<a class="reference external" href="http://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html#numpy.array" title="(in NumPy v1.11)"><em>numpy.array</em></a>) &#8211; Samples drawn according do kde2. Will be used as sample to
calculate the expected values according to &#8216;Q&#8217; as detailed before.</li>
<li><strong>ln_P1_exp_P1</strong> (<em>float or None</em>) &#8211; Use this value for <span class="math">\(\langle{}log(P(x))\rangle{}_P\)</span>; if None,
calculate it instead</li>
<li><strong>ln_P2_exp_P2</strong> (<em>float or None</em>) &#8211; Use this value for <span class="math">\(\langle{}log(Q(x))\rangle{}_Q\)</span>; if
None, calculate it instead</li>
<li><strong>ln_P1P2_exp_P1</strong> (<em>float or None</em>) &#8211; Use this value for
<span class="math">\(\langle{}log(0.5*(P(x)+Q(x)))\rangle{}_P\)</span>;
if None, calculate it instead</li>
<li><strong>ln_P1P2_exp_P2</strong> (<em>float or None</em>) &#8211; Use this value for
<span class="math">\(\langle{}log(0.5*(P(x)+Q(x)))\rangle{}_Q\)</span>;
if None, calculate it instead</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>djs</strong> &#8211;
Jensen-Shannon divergence calculated according to the dimensionality
reduction method</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="http://docs.python.org/library/functions.html#float" title="(in Python v2.7)">float</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="MDAnalysis.analysis.encore.similarity.discrete_jensen_shannon_divergence">
<code class="descclassname">MDAnalysis.analysis.encore.similarity.</code><code class="descname">discrete_jensen_shannon_divergence</code><span class="sig-paren">(</span><em>pA</em>, <em>pB</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/MDAnalysis/analysis/encore/similarity.html#discrete_jensen_shannon_divergence"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MDAnalysis.analysis.encore.similarity.discrete_jensen_shannon_divergence" title="Permalink to this definition">¶</a></dt>
<dd><p>Jensen-Shannon divergence between discrete probability distributions.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>pA</strong> (<em>iterable of floats</em>) &#8211; First discrete probability density function</li>
<li><strong>pB</strong> (<em>iterable of floats</em>) &#8211; Second discrete probability density function</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>djs</strong> &#8211;
Discrete Jensen-Shannon divergence</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="http://docs.python.org/library/functions.html#float" title="(in Python v2.7)">float</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="MDAnalysis.analysis.encore.similarity.discrete_kullback_leibler_divergence">
<code class="descclassname">MDAnalysis.analysis.encore.similarity.</code><code class="descname">discrete_kullback_leibler_divergence</code><span class="sig-paren">(</span><em>pA</em>, <em>pB</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/MDAnalysis/analysis/encore/similarity.html#discrete_kullback_leibler_divergence"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MDAnalysis.analysis.encore.similarity.discrete_kullback_leibler_divergence" title="Permalink to this definition">¶</a></dt>
<dd><p>Kullback-Leibler divergence between discrete probability distribution.
Notice that since this measure is not symmetric ::
<span class="math">\(d_{KL}(p_A,p_B) != d_{KL}(p_B,p_A)\)</span></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>pA</strong> (<em>iterable of floats</em>) &#8211; First discrete probability density function</li>
<li><strong>pB</strong> (<em>iterable of floats</em>) &#8211; Second discrete probability density function</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>dkl</strong> &#8211;
Discrete Kullback-Liebler divergence</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="http://docs.python.org/library/functions.html#float" title="(in Python v2.7)">float</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">MDAnalysis.analysis.encore.similarity.</code><code class="descname">dres</code><span class="sig-paren">(</span><em>ensembles</em>, <em>selection='name CA'</em>, <em>dimensionality_reduction_method=&lt;MDAnalysis.analysis.encore.dimensionality_reduction.DimensionalityReductionMethod.StochasticProximityEmbeddingNative object&gt;</em>, <em>distance_matrix=None</em>, <em>nsamples=1000</em>, <em>estimate_error=False</em>, <em>bootstrapping_samples=100</em>, <em>ncores=1</em>, <em>calc_diagonal=False</em>, <em>allow_collapsed_result=True</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/MDAnalysis/analysis/encore/similarity.html#dres"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Calculates the Dimensional Reduction Ensemble Similarity (DRES) between
ensembles using the Jensen-Shannon divergence as described in
<a class="reference internal" href="../../references.html#tiberti2015" id="id8">[Tiberti2015]</a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>ensembles</strong> (<a class="reference external" href="http://docs.python.org/library/functions.html#list" title="(in Python v2.7)"><em>list</em></a>) &#8211; List of ensemble objects for similarity measurements</li>
<li><strong>selection</strong> (<em>str, optional</em>) &#8211; Atom selection string in the MDAnalysis format. Default is &#8220;name CA&#8221;</li>
<li><strong>dimensionality_reduction_method</strong> &#8211; A single or a list of instances of the DimensionalityReductionMethod
classes from the dimensionality_reduction module. Different parameters
for the same method can be explored by adding different instances of
the same dimensionality reduction class. Provided methods are the
Stochastic Proximity Embedding (default) and the Principal Component
Analysis.</li>
<li><strong>distance_matrix</strong> (<a class="reference internal" href="utils.html#MDAnalysis.analysis.encore.utils.TriangularMatrix" title="MDAnalysis.analysis.encore.utils.TriangularMatrix"><em>encore.utils.TriangularMatrix</em></a>) &#8211; conformational distance matrix, It will be calculated on the fly
from the ensemble data if it is not provided.</li>
<li><strong>nsamples</strong> (<em>int, optional</em>) &#8211; Number of samples to be drawn from the ensembles (default is 1000).
This is used to resample the density estimates and calculate the
Jensen-Shannon divergence between ensembles.</li>
<li><strong>estimate_error</strong> (<em>bool, optional</em>) &#8211; Whether to perform error estimation (default is False)</li>
<li><strong>bootstrapping_samples</strong> (<em>int, optional</em>) &#8211; number of samples to be used for estimating error.</li>
<li><strong>ncores</strong> (<em>int, optional</em>) &#8211; Maximum number of cores to be used (default is 1).</li>
<li><strong>calc_diagonal</strong> (<em>bool, optional</em>) &#8211; Whether to calculate the diagonal of the similarity scores
(i.e. the simlarities of every ensemble against itself).
If this is False (default), 0.0 will be used instead.</li>
<li><strong>allow_collapsed_result</strong> (<em>bool, optional</em>) &#8211; Whether a return value of a list of one value should be collapsed
into just the value.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><p><strong>dres, details</strong> &#8211;
dres contains the similarity values, arranged in numpy.array.
If one number of dimensions is provided as an integer,
the output will be a 2-dimensional square symmetrical numpy.array.
The order of the matrix elements depends on the order of the
input ensemble: for instance, if</p>
<blockquote>
<div><p>ensemble = [ens1, ens2, ens3]</p>
</div></blockquote>
<p>then the matrix elements [0,2] and [2,0] will both contain the
similarity value between ensembles ens1 and ens3.
Elaborating on the previous example, if <em>n</em> ensembles are given and <em>m</em>
methods are provided the output will be a list of <em>m</em> arrays
ordered by the input sequence of methods, each with a <em>n*x*n</em>
symmetrical similarity matrix.</p>
<p>details provide an array of the reduced_coordinates.</p>
</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy.array, numpy.array</p>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>To calculate the similarity, the method first projects the ensembles into
lower dimensions by using the Stochastic Proximity Embedding (or others)
algorithm. A gaussian kernel-based density estimation method is then used
to estimate the probability density for each ensemble which is then used
to compute the Jensen-Shannon divergence between each pair of ensembles.</p>
<p>In the Jensen-Shannon divergence the upper bound of ln(2) signifies
no similarity between the two ensembles, the lower bound, 0.0,
signifies identical ensembles. However, due to the stochastic nature of
the dimensional reduction in <a class="reference internal" href="#MDAnalysis.analysis.encore.similarity.dres" title="MDAnalysis.analysis.encore.similarity.dres"><code class="xref py py-func docutils literal"><span class="pre">dres()</span></code></a>, two identical ensembles will
not necessarily result in an exact 0.0 estimate of the similarity but
will be very close. For the same reason, calculating the similarity with
the <a class="reference internal" href="#MDAnalysis.analysis.encore.similarity.dres" title="MDAnalysis.analysis.encore.similarity.dres"><code class="xref py py-func docutils literal"><span class="pre">dres()</span></code></a> twice will not result in two identical numbers; small
differences have to be expected.</p>
<p class="rubric">Examples</p>
<p>To calculate the Dimensional Reduction Ensemble similarity, two ensembles
are created as Universe objects from a topology file and two trajectories.
The topology- and trajectory files used are obtained from the MDAnalysis
test suite for two different simulations of the protein AdK. To run the
examples see the module <a class="reference internal" href="#examples">Examples</a> for how to import the files.
Here the simplest case of comparing just two instances of <code class="xref py py-class docutils literal"><span class="pre">Universe</span></code> is
illustrated:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ens1</span> <span class="o">=</span> <span class="n">Universe</span><span class="p">(</span><span class="n">PSF</span><span class="p">,</span><span class="n">DCD</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ens2</span> <span class="o">=</span> <span class="n">Universe</span><span class="p">(</span><span class="n">PSF</span><span class="p">,</span><span class="n">DCD2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">DRES</span><span class="p">,</span> <span class="n">details</span> <span class="o">=</span> <span class="n">encore</span><span class="o">.</span><span class="n">dres</span><span class="p">([</span><span class="n">ens1</span><span class="p">,</span><span class="n">ens2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">DRES</span>
<span class="go">[[ 0.          0.67996043]</span>
<span class="go"> [ 0.67996043  0.        ]]</span>
</pre></div>
</div>
<p>In addition to the quantitative similarity estimate, the dimensional
reduction can easily be visualized, see the <code class="docutils literal"><span class="pre">Example</span></code> section in
<code class="xref py py-mod docutils literal"><span class="pre">MDAnalysis.analysis.encore.dimensionality_reduction.reduce_dimensionality`</span></code></p>
<p>To use a different dimensional reduction methods, simply set the
parameter dimensionality_reduction_method. Likewise, different parameters
for the same clustering method can be explored by adding different
instances of the same method  class:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">DRES</span><span class="p">,</span> <span class="n">details</span> <span class="o">=</span> <span class="n">encore</span><span class="o">.</span><span class="n">dres</span><span class="p">([</span><span class="n">ens1</span><span class="p">,</span><span class="n">ens2</span><span class="p">],</span>
<span class="go">                                dimensionality_reduction_method = encore.PrincipalComponentAnalysis(dimension=2))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">DRES</span>
<span class="go">[[ 0.          0.69314718]</span>
<span class="go"> [ 0.69314718  0.        ]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="MDAnalysis.analysis.encore.similarity.dres_convergence">
<code class="descclassname">MDAnalysis.analysis.encore.similarity.</code><code class="descname">dres_convergence</code><span class="sig-paren">(</span><em>original_ensemble</em>, <em>window_size</em>, <em>selection='name CA'</em>, <em>dimensionality_reduction_method=&lt;MDAnalysis.analysis.encore.dimensionality_reduction.DimensionalityReductionMethod.StochasticProximityEmbeddingNative object&gt;</em>, <em>nsamples=1000</em>, <em>ncores=1</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/MDAnalysis/analysis/encore/similarity.html#dres_convergence"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MDAnalysis.analysis.encore.similarity.dres_convergence" title="Permalink to this definition">¶</a></dt>
<dd><p>Use the DRES to evaluate the convergence of the ensemble/trajectory.
DRES will be calculated between the whole trajectory contained in an
ensemble and windows of such trajectory of increasing sizes, so that
the similarity values should gradually drop to zero. The rate at which
the value reach zero will be indicative of how much the trajectory
keeps on resampling the same ares of the conformational space, and
therefore of convergence.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>original_ensemble</strong> (<a class="reference internal" href="../../core/AtomGroup.html#MDAnalysis.core.AtomGroup.Universe" title="MDAnalysis.core.AtomGroup.Universe"><code class="xref py py-class docutils literal"><span class="pre">Universe</span></code></a> object) &#8211; ensemble containing the trajectory whose convergence has to estimated</li>
<li><strong>window_size</strong> (<a class="reference external" href="http://docs.python.org/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; Size of window to be used, in number of frames</li>
<li><strong>selection</strong> (<em>str, optional</em>) &#8211; Atom selection string in the MDAnalysis format. Default is &#8220;name CA&#8221;</li>
<li><strong>dimensionality_reduction_method</strong> &#8211; A single or a list of instances of the DimensionalityReductionMethod
classes from the dimensionality_reduction module. Different parameters
for the same method can be explored by adding different instances of
the same dimensionality reduction class.</li>
<li><strong>nsamples</strong> (<em>int, optional</em>) &#8211; Number of samples to be drawn from the ensembles (default is 1000).
This is akin to the nsamples parameter of dres().</li>
<li><strong>ncores</strong> (<em>int, optional</em>) &#8211; Maximum number of cores to be used (default is 1).</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>out</strong> &#8211;
array of shape (number_of_frames / window_size, preference_values).</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">np.array</p>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Example</p>
<p>To calculate the convergence of a trajectory using the DRES
method, a Universe object is created from a topology file and the
trajectory. The topology- and trajectory files used are obtained from the
MDAnalysis test suite for two different simulations of the protein AdK.
To run the examples see the module <a class="reference internal" href="#examples">Examples</a> for how to import the files.
Here the simplest case of evaluating the convergence is illustrated by
splitting the trajectory into a window_size of 10 frames :</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ens1</span> <span class="o">=</span> <span class="n">Universe</span><span class="p">(</span><span class="n">PSF</span><span class="p">,</span><span class="n">DCD</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dres_conv</span> <span class="o">=</span> <span class="n">encore</span><span class="o">.</span><span class="n">dres_convergence</span><span class="p">(</span><span class="n">ens1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">dres_conv</span>
<span class="go">[[ 0.5295528 ]</span>
<span class="go"> [ 0.40716539]</span>
<span class="go"> [ 0.31158669]</span>
<span class="go"> [ 0.25314041]</span>
<span class="go"> [ 0.20447271]</span>
<span class="go"> [ 0.13212364]</span>
<span class="go"> [ 0.06979114]</span>
<span class="go"> [ 0.05214759]</span>
<span class="go"> [ 0.        ]]</span>
</pre></div>
</div>
<p>Here, the rate at which the values reach zero will be indicative of how
much the trajectory keeps on resampling the same ares of the conformational
space, and therefore of convergence.</p>
</dd></dl>

<dl class="function">
<dt id="MDAnalysis.analysis.encore.similarity.gen_kde_pdfs">
<code class="descclassname">MDAnalysis.analysis.encore.similarity.</code><code class="descname">gen_kde_pdfs</code><span class="sig-paren">(</span><em>embedded_space</em>, <em>ensemble_assignment</em>, <em>nensembles</em>, <em>nsamples</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/MDAnalysis/analysis/encore/similarity.html#gen_kde_pdfs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MDAnalysis.analysis.encore.similarity.gen_kde_pdfs" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate Kernel Density Estimates (KDE) from embedded spaces and
elaborate the coordinates for later use.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>embedded_space</strong> (<a class="reference external" href="http://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html#numpy.array" title="(in NumPy v1.11)"><em>numpy.array</em></a>) &#8211; Array containing the coordinates of the embedded space</li>
<li><strong>ensemble_assignment</strong> (<a class="reference external" href="http://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html#numpy.array" title="(in NumPy v1.11)"><em>numpy.array</em></a>) &#8211; Array containing one int per ensemble conformation. These allow to
distinguish, in the complete embedded space, which conformations
belong to each ensemble. For instance if ensemble_assignment
is [1,1,1,1,2,2], it means that the first four conformations belong
to ensemble 1 and the last two to ensemble 2</li>
<li><strong>nensembles</strong> (<a class="reference external" href="http://docs.python.org/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; Number of ensembles</li>
<li><strong>nsamples</strong> (<a class="reference external" href="http://docs.python.org/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; samples to be drawn from the ensembles. Will be required in
a later stage in order to calculate dJS.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><strong>kdes</strong> (<em>scipy.stats.gaussian_kde</em>) &#8211;
KDEs calculated from ensembles</li>
<li><strong>resamples</strong> (<em>list of numpy.array</em>) &#8211;
For each KDE, draw samples according to the probability distribution
of the KDE mixture model</li>
<li><strong>embedded_ensembles</strong> (<em>list of numpy.array</em>) &#8211;
List of numpy.array containing, each one, the elements of the
embedded space belonging to a certain ensemble</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="MDAnalysis.analysis.encore.similarity.harmonic_ensemble_similarity">
<code class="descclassname">MDAnalysis.analysis.encore.similarity.</code><code class="descname">harmonic_ensemble_similarity</code><span class="sig-paren">(</span><em>sigma1</em>, <em>sigma2</em>, <em>x1</em>, <em>x2</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/MDAnalysis/analysis/encore/similarity.html#harmonic_ensemble_similarity"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MDAnalysis.analysis.encore.similarity.harmonic_ensemble_similarity" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the harmonic ensemble similarity measure
as defined in <a class="reference internal" href="../../references.html#tiberti2015" id="id9">[Tiberti2015]</a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>sigma1</strong> (<a class="reference external" href="http://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html#numpy.array" title="(in NumPy v1.11)"><em>numpy.array</em></a>) &#8211; Covariance matrix for the first ensemble.</li>
<li><strong>sigma2</strong> (<a class="reference external" href="http://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html#numpy.array" title="(in NumPy v1.11)"><em>numpy.array</em></a>) &#8211; Covariance matrix for the second ensemble.</li>
<li><strong>x1</strong> (<a class="reference external" href="http://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html#numpy.array" title="(in NumPy v1.11)"><em>numpy.array</em></a>) &#8211; Mean for the estimated normal multivariate distribution of the first
ensemble.</li>
<li><strong>x2</strong> (<a class="reference external" href="http://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html#numpy.array" title="(in NumPy v1.11)"><em>numpy.array</em></a>) &#8211; Mean for the estimated normal multivariate distribution of the second
ensemble.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>dhes</strong> &#8211;
harmonic similarity measure</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="http://docs.python.org/library/functions.html#float" title="(in Python v2.7)">float</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">MDAnalysis.analysis.encore.similarity.</code><code class="descname">hes</code><span class="sig-paren">(</span><em>ensembles</em>, <em>selection='name CA'</em>, <em>cov_estimator='shrinkage'</em>, <em>mass_weighted=True</em>, <em>align=False</em>, <em>details=False</em>, <em>estimate_error=False</em>, <em>bootstrapping_samples=100</em>, <em>calc_diagonal=False</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/MDAnalysis/analysis/encore/similarity.html#hes"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Calculates the Harmonic Ensemble Similarity (HES) between ensembles using
the symmetrized version of Kullback-Leibler divergence as described
in <a class="reference internal" href="../../references.html#tiberti2015" id="id10">[Tiberti2015]</a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>ensembles</strong> (<a class="reference external" href="http://docs.python.org/library/functions.html#list" title="(in Python v2.7)"><em>list</em></a>) &#8211; List of Universe objects for similarity measurements.</li>
<li><strong>selection</strong> (<em>str, optional</em>) &#8211; Atom selection string in the MDAnalysis format. Default is &#8220;name CA&#8221;</li>
<li><strong>cov_estimator</strong> (<em>str, optional</em>) &#8211; Covariance matrix estimator method, either shrinkage, <cite>shrinkage</cite>,
or Maximum Likelyhood, <cite>ml</cite>. Default is shrinkage.</li>
<li><strong>mass_weighted</strong> (<em>bool, optional</em>) &#8211; Whether to perform mass-weighted covariance matrix estimation
(default is True).</li>
<li><strong>align</strong> (<em>bool, optional</em>) &#8211; Whether to align the ensembles before calculating their similarity.
Note: this changes the ensembles in-place, and will thus leave your
ensembles in an altered state.
(default is False)</li>
<li><strong>details</strong> (<em>bool, optional</em>) &#8211; Save the mean and covariance matrix for each
ensemble in a numpy array (default is False).</li>
<li><strong>estimate_error</strong> (<em>bool, optional</em>) &#8211; Whether to perform error estimation (default is False).</li>
<li><strong>bootstrapping_samples</strong> (<em>int, optional</em>) &#8211; Number of times the similarity matrix will be bootstrapped (default
is 100), only if estimate_error is True.</li>
<li><strong>calc_diagonal</strong> (<em>bool, optional</em>) &#8211; Whether to calculate the diagonal of the similarity scores
(i.e. the similarities of every ensemble against itself).
If this is False (default), 0.0 will be used instead.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Harmonic similarity measurements between each pair of ensembles.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy.array (bidimensional)</p>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>The method assumes that each ensemble is derived from a multivariate normal
distribution. The mean and covariance matrix are, thus, estimatated from
the distribution of each ensemble and used for comparision by the
symmetrized version of Kullback-Leibler divergence defined as:</p>
<div class="math">
\[D_{KL}(P(x) || Q(x)) = \int_{-\infty}^{\infty}P(x_i)
ln(P(x_i)/Q(x_i)) = \langle{}ln(P(x))\rangle{}_P -
\langle{}ln(Q(x))\rangle{}_P\]</div>
<p>where the <span class="math">\(\langle{}.\rangle{}_P\)</span> denotes an expectation
calculated under the distribution P.</p>
<p>For each ensemble, the  mean conformation is estimated as the average over
the ensemble, and the covariance matrix is calculated by default using a
shrinkage estimation method (or by a maximum-likelihood method,
optionally).</p>
<p>Note that the symmetrized version of the Kullback-Leibler divergence has no
upper bound (unlike the Jensen-Shannon divergence used by for instance CES and DRES).</p>
<p>When using this similarity measure, consider whether you want to align
the ensembles first (see example below).</p>
<p class="rubric">Example</p>
<p>To calculate the Harmonic Ensemble similarity, two ensembles are created
as Universe objects from a topology file and two trajectories. The
topology- and trajectory files used are obtained from the MDAnalysis
test suite for two different simulations of the protein AdK. To run the
examples see the module <a class="reference internal" href="#examples">Examples</a> for how to import the files:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ens1</span> <span class="o">=</span> <span class="n">Universe</span><span class="p">(</span><span class="n">PSF</span><span class="p">,</span> <span class="n">DCD</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ens2</span> <span class="o">=</span> <span class="n">Universe</span><span class="p">(</span><span class="n">PSF</span><span class="p">,</span> <span class="n">DCD2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">HES</span><span class="p">,</span> <span class="n">details</span> <span class="o">=</span> <span class="n">encore</span><span class="o">.</span><span class="n">hes</span><span class="p">([</span><span class="n">ens1</span><span class="p">,</span> <span class="n">ens2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">HES</span>
<span class="go">[[        0.          38279683.95892926]</span>
<span class="go"> [ 38279683.95892926         0.        ]]</span>
</pre></div>
</div>
<p>You can use the align=True option to align the ensembles first. This will
align everything to the current timestep in the first ensemble. Note that
this changes the ens1 and ens2 objects:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">encore</span><span class="o">.</span><span class="n">hes</span><span class="p">([</span><span class="n">ens1</span><span class="p">,</span> <span class="n">ens2</span><span class="p">],</span> <span class="n">align</span><span class="o">=</span><span class="bp">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">[[    0.          6880.34140106]</span>
<span class="go">[ 6880.34140106     0.        ]]</span>
</pre></div>
</div>
<p>Alternatively, for greater flexibility in how the alignment should be done
you can call the rms_fit_trj function manually:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">MDAnalysis.analysis</span> <span class="kn">import</span> <span class="n">align</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">align</span><span class="o">.</span><span class="n">rms_fit_trj</span><span class="p">(</span><span class="n">ens1</span><span class="p">,</span> <span class="n">ens1</span><span class="p">,</span> <span class="n">select</span><span class="o">=</span><span class="s2">&quot;name CA&quot;</span><span class="p">,</span> <span class="n">in_memory</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">align</span><span class="o">.</span><span class="n">rms_fit_trj</span><span class="p">(</span><span class="n">ens2</span><span class="p">,</span> <span class="n">ens1</span><span class="p">,</span> <span class="n">select</span><span class="o">=</span><span class="s2">&quot;name CA&quot;</span><span class="p">,</span> <span class="n">in_memory</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">encore</span><span class="o">.</span><span class="n">hes</span><span class="p">([</span><span class="n">ens1</span><span class="p">,</span> <span class="n">ens2</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">[[    0.          7032.19607004]</span>
<span class="go"> [ 7032.19607004     0.        ]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="MDAnalysis.analysis.encore.similarity.prepare_ensembles_for_convergence_increasing_window">
<code class="descclassname">MDAnalysis.analysis.encore.similarity.</code><code class="descname">prepare_ensembles_for_convergence_increasing_window</code><span class="sig-paren">(</span><em>ensemble</em>, <em>window_size</em>, <em>selection='name CA'</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/MDAnalysis/analysis/encore/similarity.html#prepare_ensembles_for_convergence_increasing_window"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MDAnalysis.analysis.encore.similarity.prepare_ensembles_for_convergence_increasing_window" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate ensembles to be fed to ces_convergence or dres_convergence
from a single ensemble. Basically, the different slices the algorithm
needs are generated here.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>ensemble</strong> (<a class="reference internal" href="../../core/AtomGroup.html#MDAnalysis.core.AtomGroup.Universe" title="MDAnalysis.core.AtomGroup.Universe"><code class="xref py py-class docutils literal"><span class="pre">Universe</span></code></a> object) &#8211; Input ensemble</li>
<li><strong>window_size</strong> (<a class="reference external" href="http://docs.python.org/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; size of the window (in number of frames) to be used</li>
<li><strong>selection</strong> (<a class="reference external" href="http://docs.python.org/library/functions.html#str" title="(in Python v2.7)"><em>str</em></a>) &#8211; Atom selection string in the MDAnalysis format. Default is &#8220;name CA&#8221;</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">The original ensemble is divided into different ensembles, each being
a window_size-long slice of the original ensemble. The last
ensemble will be bigger if the length of the input ensemble
is not exactly divisible by window_size.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">tmp_ensembles</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="MDAnalysis.analysis.encore.similarity.write_output">
<code class="descclassname">MDAnalysis.analysis.encore.similarity.</code><code class="descname">write_output</code><span class="sig-paren">(</span><em>matrix</em>, <em>base_fname=None</em>, <em>header=''</em>, <em>suffix=''</em>, <em>extension='dat'</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/MDAnalysis/analysis/encore/similarity.html#write_output"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#MDAnalysis.analysis.encore.similarity.write_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Write output matrix with a nice format, to stdout and optionally a file.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>matrix</strong> (<a class="reference internal" href="utils.html#MDAnalysis.analysis.encore.utils.TriangularMatrix" title="MDAnalysis.analysis.encore.utils.TriangularMatrix"><em>encore.utils.TriangularMatrix</em></a>) &#8211; Matrix containing the values to be printed</li>
<li><strong>base_fname</strong> (<a class="reference external" href="http://docs.python.org/library/functions.html#str" title="(in Python v2.7)"><em>str</em></a>) &#8211; Basic filename for output. If None, no files will be written, and
the matrix will be just printed on standard output</li>
<li><strong>header</strong> (<a class="reference external" href="http://docs.python.org/library/functions.html#str" title="(in Python v2.7)"><em>str</em></a>) &#8211; Text to be written just before the matrix</li>
<li><strong>suffix</strong> (<a class="reference external" href="http://docs.python.org/library/functions.html#str" title="(in Python v2.7)"><em>str</em></a>) &#8211; String to be concatenated to basename, in order to get the final
file name</li>
<li><strong>extension</strong> (<a class="reference external" href="http://docs.python.org/library/functions.html#str" title="(in Python v2.7)"><em>str</em></a>) &#8211; Extension for the output file</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="clustering.html" title="3.2.6.1.2. Clustering"
             >next</a> |</li>
        <li class="right" >
          <a href="../encore.html" title="3.2.6. ENCORE Ensemble Similarity Calculations — MDAnalysis.analysis.encore"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../index.html">MDAnalysis 0.16.0-dev0 documentation</a> &raquo;</li>
          <li class="nav-item nav-item-1"><a href="../../analysis_modules.html" >3. Analysis modules</a> &raquo;</li>
          <li class="nav-item nav-item-2"><a href="../encore.html" >3.2.6. ENCORE Ensemble Similarity Calculations &#8212; <code class="docutils literal"><span class="pre">MDAnalysis.analysis.encore</span></code></a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &copy; Copyright 2005-2015, Naveen Michaud-Agrawal, Elizabeth J. Denning, Christian Beckstein (logo), Joshua L. Adelman, Balasubramanian, Jonathan Barnoud, Tone Bengtsen, Alejandro Bernardin, Wouter Boomsma, Bart Bruininks, Sébastien Buchoux, David Caplan, Matthieu Chavent, Robert Delgado, John Detlefs, Xavier Deupi, Jan Domanski, David L. Dotson, Lennard van der Feltz, Philip Fowler, Joseph Goose, Richard J. Gowers, Lukas Grossar, Abhinav Gupta, Benjamin Hall, Eugen Hruska, Kyle J. Huston, Joe Jordan, Max Linke, Jinju Lu, Robert McGibbon, Manuel Nuno Melo, Fiona Naughton, Alex Nesterenko, Hai Nguyen, Mattia F. Palermo, Danny Parton, Joshua L. Phillips, Tyler Reddy, Paul Rigor, Carlos Yanez S., Utkarsh Saxena, Sean L. Seyler, Andy Somogyi, Caio S. Souza, Lukas Stelzl, Gorman Stock, Matteo Tiberti, Isaac Virshup, Zhuyi Xue, and Oliver Beckstein.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.5.
    </div>
  </body>
</html>